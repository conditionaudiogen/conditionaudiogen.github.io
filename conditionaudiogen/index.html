<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="generator" content="Hugo 0.66.0" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/f8.4/styles/github.min.css">
<link rel="stylesheet" href="../css/normalize.css">
<link rel="stylesheet" href="../css/skeleton.css">
<link rel="stylesheet" href="../css/custom.css">
<link rel="alternate" href="index.xml" type="application/rss+xml" title="Speech Research">
<link rel="shortcut icon" href="favicon.png" type="image/x-icon" />
<title>Audio Generation with Multiple Conditional Diffusion Model - Speech Research</title>
</head>
<body>

<div class="container">

	<header role="banner">
	</header>
	<main role="main">
		<article itemscope itemtype="https://schema.org/BlogPostinCg">
            <h1 class="entry-title" itemprop="headline">Audio Generation with Multiple Conditional Diffusion Model</h1>

			<section itemprop="entry-text">
				<br>

<h2 id="abstract">Abstract</h2>
<p> Text cannot encompass all the information in audio, leading to restricted controllability in audio generation when relying solely on text. To address this issue, we propose a model that enhances the controllability of existing pre-trained text-to-audio models by incorporating other conditions including content (timestamp) and style (pitch contour and energy contour) information as a supplement to the text, which achieves fine-grained control over the temporal order, pitch, and energy. To preserve the diversity of generation, we employ a trainable control condition encoder, which enhances the comprehension of sound events by a large language model, and a Fusion-Net to encode and fuse the additional conditions, while keeping the weights of the pre-trained text-to-audio model frozen. Due to the lack of suitable datasets and evaluation metrics for benchmarking, we consolidate the existing datasets into a new dataset comprising the audio and the corresponding conditions and use a series of metrics to evaluate the controllability performance. Experimental results demonstrate that our model successfully achieves fine-grained control and possesses zero-shot capability to accomplish controllable audio generation. Audio samples and our dataset are publicly available. </p>


<h2 id="content">Content</h2>
<b><a href="#dataset">1. Dataset</a></b><br>
<a href="#promptspeech">1.1 AudioCondition</a><br>
<b><a href="#audio samples">2. Audio Samples</a></b><br>
<a href="#Part 1">2.1 Comparison of Different Models</a><br>
<a href="#Part 2">2.2 Comparison of Different Control Conditions</a><br>
<a href="#Part 3">2.3 Comparison of Different Text Conditions</a><br>

<h2 id="dataset">1. Dataset</h2>
<p> Given that there are no TTA datasets with both text and control conditions, we integrate the existing datasets to a new dataset called AudioCondition that consists of the audio along with the corresponding conditions. The text condition is obtained from WavCaps, a caption dataset based on ChatGPT and processed through a three-stage pipeline to filter noisy data and produce high-quality text. For the timestamp, we obtained from AudiosetStrong, a subset of Audioset, containing 1.8M audio with frame-level timestamp for 456 sound events. For the pitch contour and energy contour, we extract the value of them from audio with signal processing tools. Due to the limited number of sound events supported by the current sound event detection (SED) models, we only select audio that includes sound events supported by SED models for test set. We split AudioCondition into three sets: 89557 samples for training, 1398 samples for validation, and 1110 samples for testing, which is publicly available.</p>
<p> Note that we also release all of the test set that here. For the timestamp, you can find in the "data_numpy" of the dataset, and for the pitch contour and energy contour, you can obtain them using signal processing tools.</p>

<h3 id="promptspeech">1.1 AudioCondition</h3>
<p> You can download AudioCondition from the table below and the number in the table corresponds to the amount of downloaded data. </p>

<table><thead>
<tr>
<th style="text-align: center">Train</th>
<th style="text-align: center">Validation</th>
<th style="text-align: center">Test</th>
<th style="text-align: center">Test-full</th>
<th style="text-align: center">Audio</th>
</tr></thead><tbody>
<tr>
<td><a href="../dataset/train_strong.zip">89557</a></td>
<td><a href="../dataset/val_strong.zip">1398</a></td>
<td><a href="../dataset/test_strong.zip">1110</a></td>
<td><a href="../dataset/test_strong_full.zip">15866</a></td>
<td><a href="https://research.google.com/audioset/download_strong.html">120459</a></td>
</tr>
</tbody>
</table>

<h2 id="audio samples">2. Audio Samples</h2>
<p> The following parts are the audio samples from ground-truth recordings (denoted as GT), our model, and Tango. We demonstrate from the following three aspects: </p>
<p> <b>Comparison of Different Models</b>: we aim to show that we can generate audio that is more consistent with the ground-truth recordings under the help of control conditions.</p>
<p> <b>Comparison of Different Control Conditions</b>: we aim to show that we can control the attributes of audio with different control conditions.</p>
<p> <b>Comparison of Different Text Conditions</b>: we aim to show that we can generate different audio using different text control conditions while maintaining consistency with the control conditions.</p>

<h3 id="Part 1">2.1 Comparison of Different Models</h3>
<p> Note that audio samples in this part are from ground-truth recordings, our model, and Tango, which show that our model can generate audio that is more consistent with the ground-truth recordings under the help of control conditions.</p>
<p> Our model takes the text and control conditions as input, while Tango only takes the text conditions as input. </p>

<h4 id="Temporal Order1">2.1.1 Temporal Order</h4>
<p> We only need sound effects or noise during 1-3 seconds, but in the entire audio generated by Tango, there are sound effects or noise present throughout. </p>
<p>[Our Model, Tango, GT]: Text Condition: <em> Various sound effects and noise are present. </em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Our Model</th>
<th style="text-align: center">Tango</th>
<th style="text-align: center">GT</th>
</tr>
<tr>
<td style="text-align: center"><img src='../figure/image5.jpeg'/></td>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio8.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio10.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio9.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>

<!--
<p>[Our model, Tango, GT]: Text Condition: <em> The sound of a door closing in a small room is the only sound in this recording. </em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Our Model</th>
<th style="text-align: center">Tango</th>
<th style="text-align: center">GT</th>
</tr>
<tr>
<td style="text-align: center"><img src='../figure/image4.jpeg'/></td>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio6.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio12.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio7.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>

<p>[Our model, Tango, GT]: Text Condition: <em> Music and male singing can be heard. </em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Our Model</th>
<th style="text-align: center">Tango</th>
<th style="text-align: center">GT</th>
</tr>
<tr>
<td style="text-align: center"><img src='../figure/image2.jpeg'/></td>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio1.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio11.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio2.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>
-->


<h4 id="Pitch1">2.1.2 Pitch</h4>
<p> We only need a high pitch sound (train whistle) at the beginning, but in the audio generated by Tango, it appears both at the beginning and the end. </p>
<p>[Our Model, Tango, GT]: Text Condition: <em> The sounds of a train and clicking wheels can be heard. </em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Our Model</th>
<th style="text-align: center">Tango</th>
<th style="text-align: center">GT</th>
</tr>
<tr>
<td style="text-align: center"><img src='../figure/image6.jpeg'/></td>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio14.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio13.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio15.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>

<!--
<p>[Our model, Tango, GT]: Text Condition: <em> Waves, surf, and breathing sounds are heard. </em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Our Model</th>
<th style="text-align: center">Tango</th>
<th style="text-align: center">GT</th>
</tr>
<tr>
<td style="text-align: center"><img src='../figure/image7.jpeg'/></td>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio21.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio16.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio17.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>

<p>[Our model, Tango, GT]: Text Condition: <em> People breathe, make human sounds, and tap with background noise. </em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Our Model</th>
<th style="text-align: center">Tango</th>
<th style="text-align: center">GT</th>
</tr>
<tr>
<td style="text-align: center"><img src='../figure/image8.jpeg'/></td>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio19.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio20.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio18.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>
-->
<h4 id="Energy1">2.1.3 Energy</h4>
<p> We only need two high energy segments, but in the audio generated by Tango, it has a lot of energy fluctuations. </p>
<p>[Our Model, Tango, GT]: Text Condition: <em> Mechanisms, clicking, a buzzer, an alarm, and breathing are heard. </em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Our Model</th>
<th style="text-align: center">Tango</th>
<th style="text-align: center">GT</th>
</tr>
<tr>
<td style="text-align: center"><img src='../figure/image11.jpeg'/></td>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio26.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio27.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio25.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>

<!--
<p>[Our model, Tango, GT]: Text Condition: <em> A vehicle is driving on water and revving with man speaking. </em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Our Model</th>
<th style="text-align: center">Tango</th>
<th style="text-align: center">GT</th>
</tr>
<tr>
<td style="text-align: center"><img src='../figure/image10.jpeg'/></td>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio24.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio29.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio28.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>

<p>[Our model, Tango, GT]: Text Condition: <em> Music is playing. </em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Our Model</th>
<th style="text-align: center">Tango</th>
<th style="text-align: center">GT</th>
</tr>
<tr>
<td style="text-align: center"><img src='../figure/image9.jpeg'/></td>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio22.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio30.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio23.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>
-->
<h3 id="Part 2">2.2 Comparison of Different Control Conditions</h3>
<p> Note that audio samples in this part are from our model, which show that our model can control the attributes of audio with different control conditions.</p>

<h4 id="Temporal Order2">2.2.1 Temporal Order</h4>
<p> Our model accepts the timestamp of varying durations, onsets and end offsets as the control conditions, while keeping the text condition consistent. </p>
<p>Our Model-[1, 2, 3]: Text Condition: <em> Various sound effects and noise are present. </em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Our Model-1</th>
<th style="text-align: center">Our Model-2</th>
<th style="text-align: center">Our Model-3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><img src='../figure/image5.jpeg'/></td>
<td style="text-align: center"><img src='../figure/image12.jpeg'/></td>
<td style="text-align: center"><img src='../figure/image13.jpeg'/></td>
</tr>
</tbody>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio8.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio31.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio32.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>

<h4 id="Pitch2">2.2.2 Pitch</h4>
<p> Our model accepts the medium, low, and high pitch contour as the control conditions, while keeping the text condition consistent. </p>
<p>Our Model-[1, 2, 3]: Text Condition: <em> The sounds of a train and clicking wheels can be heard. </em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Our Model-1</th>
<th style="text-align: center">Our Model-2</th>
<th style="text-align: center">Our Model-3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><img src='../figure/image6.jpeg'/></td>
<td style="text-align: center"><img src='../figure/image14.jpeg'/></td>
<td style="text-align: center"><img src='../figure/image15.jpeg'/></td>
</tr>
</tbody>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio14.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio33.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio34.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>

<h4 id="Energy2">2.2.3 Energy</h4>
<p> Our model accepts the medium, low, and high energy contour as the control conditions, while keeping the text condition consistent. </p>
<p>Our Model-[1, 2, 3]: Text Condition: <em> Mechanisms, clicking, a buzzer, an alarm, and breathing are heard. </em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Our Model-1</th>
<th style="text-align: center">Our Model-2</th>
<th style="text-align: center">Our Model-3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><img src='../figure/image11.jpeg'/></td>
<td style="text-align: center"><img src='../figure/image16.jpeg'/></td>
<td style="text-align: center"><img src='../figure/image17.jpeg'/></td>
</tr>
</tbody>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio26.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio35.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio36.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>

<h3 id="Part 3">2.3 Comparison of Different Text Conditions</h3>
<p> Note that audio samples in this part are from our model, which show that our model can generate different audio using different text control conditions while maintaining consistency with the control conditions.</p>

<h4 id="Temporal Order3">2.3.1 Temporal Order</h4>
<p> Our model accepts different text conditions, while keeping the timestamp as control condition consistent. </p>
<p>Our Model-1: Text Condition: <em> The sound of a door closing in a small room is the only sound in this recording. </em></p>
<p>Our Model-2: Text Condition: <em> In this recording, the sole sound is that of a door shutting in a small room. </em></p>
<p>Our Model-3: Text Condition: <em> There is only the sound of a door closing in a small room within this recording. </em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Our Model-1</th>
<th style="text-align: center">Our Model-2</th>
<th style="text-align: center">Our Model-3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><img src='../figure/image4.jpeg'/></td>
<td style="text-align: center"><img src='../figure/image4.jpeg'/></td>
<td style="text-align: center"><img src='../figure/image4.jpeg'/></td>
</tr>
</tbody>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio6.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio37.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio38.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>

<h4 id="Pitch3">2.3.2 Pitch</h4>
<p> Our model accepts different text conditions, while keeping the pitch contour as control condition consistent. </p>
<p>Our Model-1: Text Condition: <em> Waves, surf, and breathing sounds are heard. </em></p>
<p>Our Model-2: Text Condition: <em> One can hear the sounds of waves, surf, and breathing in the recording. </em></p>
<p>Our Model-3: Text Condition: <em> The recording captures the sound of waves, surf, and breathing. </em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Our Model-1</th>
<th style="text-align: center">Our Model-2</th>
<th style="text-align: center">Our Model-3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><img src='../figure/image7.jpeg'/></td>
<td style="text-align: center"><img src='../figure/image7.jpeg'/></td>
<td style="text-align: center"><img src='../figure/image7.jpeg'/></td>
</tr>
</tbody>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio21.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio39.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio40.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>

<h4 id="Energy3">2.3.3 Energy</h4>
<p> Our model accepts different text conditions, while keeping the energy contour as control condition consistent. </p>
<p>Our Model-1: Text Condition: <em> Music is playing. </em></p>
<p>Our Model-2: Text Condition: <em> Play music. </em></p>
<p>Our Model-3: Text Condition: <em> Music can be heard. </em></p>
<table>
<thead>
<tr>
<th style="text-align: center">Our Model-1</th>
<th style="text-align: center">Our Model-2</th>
<th style="text-align: center">Our Model-3</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center"><img src='../figure/image9.jpeg'/></td>
<td style="text-align: center"><img src='../figure/image9.jpeg'/></td>
<td style="text-align: center"><img src='../figure/image9.jpeg'/></td>
</tr>
</tbody>
<tbody>
<tr>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio22.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio41.wav" autoplay/>Your browser does not support the audio element.</audio></td>
<td style="text-align: center"><audio controls="controls" ><source src="../audio/audio42.wav" autoplay/>Your browser does not support the audio element.</audio></td>
</tr>
</tbody>
</table>
				
			</section>
		</article>
	</main>

</div>

<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-139981676-1', 'auto');
	ga('send', 'pageview');
</script>

<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
     MathJax.Hub.Config({
         HTML: ["input/TeX","output/HTML-CSS"],
         TeX: {
                Macros: {
                         bm: ["\\boldsymbol{#1}", 1],
                         argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                         argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
                extensions: ["AMSmath.js","AMSsymbols.js"],
                equationNumbers: { autoNumber: "AMS" } },
         extensions: ["tex2jax.js"],
         jax: ["input/TeX","output/HTML-CSS"],
         tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true },
         "HTML-CSS": { availableFonts: ["TeX"],
                       linebreaks: { automatic: true } }
     });
 </script>

 <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       tex2jax: {
         skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
       }
     });
 </script>

 <script type="text/javascript" async
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
 </script>




</body>
</html>
